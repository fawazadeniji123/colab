{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17HFQ5-KBjQVQTzK-MHgOSH2nhBcepwP8",
      "authorship_tag": "ABX9TyNrHOzh8uihvY/Ec1rI9RdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fawazadeniji123/colab/blob/main/Kenyan_Sign_Language_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKKetxQNoUYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2183f587-e3b5-4060-a9a5-bac4dac875b9"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3RBfvy6p0FI"
      },
      "source": [
        "\n",
        "# dataset_url = 'https://zindpublic.blob.core.windows.net/private/uploads/competition_datafile/file/1569/Images.zip?sp=r&sv=2015-04-05&sr=b&st=2021-11-06T05%3A37%3A52Z&se=2021-11-06T05%3A53%3A52Z&sig=V53xLEtipw88H27RYhyw%2FEDJzbPrRE2wIyrEmiaoj4c%3D'\n",
        "# data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
        "#                                    extract=True)\n",
        "# data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dpwVaghx-Zn"
      },
      "source": [
        "# data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLH3wLSdzPFs"
      },
      "source": [
        "# !unzip \"/root/.keras/datasets/Images.zip\" -d \"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfWP4O4zPCi"
      },
      "source": [
        "# !rm -r \"/root/.keras/datasets/Images.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kcZj-Er3KTy"
      },
      "source": [
        "# data_dir = pathlib.Path(\"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W31H8RYUyBNb"
      },
      "source": [
        "# image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "# print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKfCyNqiye8-"
      },
      "source": [
        "train_csv = pd.read_csv('/content/drive/MyDrive/Kenyan Sign Language Classification/Train.csv')\n",
        "test_csv = pd.read_csv('/content/drive/MyDrive/Kenyan Sign Language Classification/Test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inTyKIrm48mQ"
      },
      "source": [
        "# train_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kun1HKviHVlb"
      },
      "source": [
        "# train_csv['Label'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnQyKa2-5KgK"
      },
      "source": [
        "# train_csv['Label'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84kL6LGl5G5Q"
      },
      "source": [
        "# test_csv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAy_DZkM5-Xs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "1eb95072-998a-4607-dd13-4c25e8cf4320"
      },
      "source": [
        "plt.hist(train_csv['Label'], bins=9, rwidth=2)\n",
        "plt.figure(figsize=(20,15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMf_TUtaUxyJ"
      },
      "source": [
        "# path = \"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset\"\n",
        "# !mkdir \"{path}/train\"\n",
        "# for label in train_csv['Label'].unique():\n",
        "#   if label == \"Enough/Satisfied\":\n",
        "#     label = \"Satisfied\"\n",
        "#   !mkdir \"{path}/train/{label}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n1UvE6B6GQz"
      },
      "source": [
        "# path = \"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset\"\n",
        "# for id, label in np.array(train_csv):\n",
        "#   if label == \"Enough/Satisfied\":\n",
        "#     label = \"Enough\"\n",
        "#   !cp \"{path}/Images/{id}.jpg\" \"{path}/train/{label}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbMFugz8ccX8"
      },
      "source": [
        "# path = \"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset\"\n",
        "# for id, _ in np.array(train_csv):\n",
        "#   !rm -r \"{path}/Images/{id}.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbb_GDTAuVaw"
      },
      "source": [
        "batch_size = 128\n",
        "img_height = 128\n",
        "img_width = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cknobnABvzHB",
        "outputId": "9439dbef-4380-45c3-a891-f647d17cf40c"
      },
      "source": [
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset/train\")\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  label_mode='categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6249 files belonging to 9 classes.\n",
            "Using 5000 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GK57KP8yuWa",
        "outputId": "b36ad0ec-bfb1-48bf-c989-93fe0e744571"
      },
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  label_mode='categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6249 files belonging to 9 classes.\n",
            "Using 1249 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1gAlyW5zthf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbabb23-d87a-4d59-9e67-6afa07b50651"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Church', 'Enough Satisfied', 'Friend', 'Love', 'Me', 'Mosque', 'Seat', 'Temple', 'You']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP-LtqRqzuou"
      },
      "source": [
        "# for image_batch, labels_batch in train_ds:\n",
        "#   print(image_batch.shape)\n",
        "#   print(labels_batch.shape)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnmBpNe2z7-R"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OTFvq-R0Im7"
      },
      "source": [
        "from tensorflow.keras import layers, Model, Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8QM6AR5gdb9"
      },
      "source": [
        "tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RciVdxPw0Ukq"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.1),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly74kpfkrgW7"
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD8hYXyW10wJ"
      },
      "source": [
        "### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAziqSJy3JCS"
      },
      "source": [
        "def create_model():\n",
        "  inputs = Input(shape=(128, 128, 3), name=\"img\")\n",
        "  x = layers.Rescaling(1./255.)(inputs)\n",
        "  x = layers.RandomFlip(\"horizontal\")(x)\n",
        "  x = layers.RandomRotation(0.2)(x)\n",
        "  data_augmentation = layers.RandomZoom(0.1)(x)\n",
        "\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\")(data_augmentation)\n",
        "  x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "  block_1_output = layers.MaxPooling2D(3)(x)\n",
        "\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  block_2_output = layers.add([x, block_1_output])\n",
        "\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "  block_3_output = layers.add([x, block_2_output])\n",
        "\n",
        "  x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
        "  x = layers.GlobalAveragePooling2D()(x)\n",
        "  x = layers.Dense(256, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(9)(x)\n",
        "\n",
        "  model = Model(inputs, outputs, name=\"toy_resnet\")\n",
        "  return model\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p580OAmR4Aux",
        "outputId": "c3107ddc-f87e-4979-dd9f-dbf9179714bc"
      },
      "source": [
        "model_1 = create_model()\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"toy_resnet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " img (InputLayer)               [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 128, 128, 3)  0           ['img[0][0]']                    \n",
            "                                                                                                  \n",
            " random_flip (RandomFlip)       (None, 128, 128, 3)  0           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " random_rotation (RandomRotatio  (None, 128, 128, 3)  0          ['random_flip[0][0]']            \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " random_zoom (RandomZoom)       (None, 128, 128, 3)  0           ['random_rotation[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 126, 126, 64  1792        ['random_zoom[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 124, 124, 32  18464       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 122, 122, 64  18496       ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 40, 40, 64)   0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 40, 40, 64)   36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 40, 40, 64)   36928       ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 40, 40, 64)   0           ['conv2d_4[0][0]',               \n",
            "                                                                  'max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 40, 40, 64)   36928       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 40, 40, 64)   36928       ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 40, 40, 64)   0           ['conv2d_6[0][0]',               \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 38, 38, 64)   36928       ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 64)          0           ['conv2d_7[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          16640       ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 9)            2313        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 242,345\n",
            "Trainable params: 242,345\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnbi0qb3PobC"
      },
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5, verbose=0,\n",
        "    mode='min',\n",
        ")\n",
        "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "    '/content/drive/MyDrive/Kenyan Sign Language Classification/checkpoint.h5', monitor='val_accuracy', verbose=1, save_best_only=True,\n",
        "    mode='max', save_freq='epoch',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDArDfB966v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3ecead-606a-4447-c68e-460c16f31245"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  model_1 = create_model()\n",
        "  model_1.compile(optimizer=tf.keras.optimizers.Adagrad(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "  history_1 = model_1.fit(\n",
        "                        train_ds, \n",
        "                        validation_data=val_ds,\n",
        "                        callbacks=[early_stop, save_best],\n",
        "                        epochs=100,\n",
        "                        batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 7.4559 - accuracy: 0.1082\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11129, saving model to /content/drive/MyDrive/Kenyan Sign Language Classification/checkpoint.h5\n",
            "40/40 [==============================] - 56s 1s/step - loss: 7.4559 - accuracy: 0.1082 - val_loss: 8.1299 - val_accuracy: 0.1113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 7.5160 - accuracy: 0.1182\n",
            "Epoch 00002: val_accuracy did not improve from 0.11129\n",
            "40/40 [==============================] - 26s 663ms/step - loss: 7.5160 - accuracy: 0.1182 - val_loss: 5.5521 - val_accuracy: 0.1113\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 7.2909 - accuracy: 0.1068\n",
            "Epoch 00003: val_accuracy improved from 0.11129 to 0.13371, saving model to /content/drive/MyDrive/Kenyan Sign Language Classification/checkpoint.h5\n",
            "40/40 [==============================] - 27s 674ms/step - loss: 7.2909 - accuracy: 0.1068 - val_loss: 5.2177 - val_accuracy: 0.1337\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 6.8395 - accuracy: 0.1082\n",
            "Epoch 00004: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 664ms/step - loss: 6.8395 - accuracy: 0.1082 - val_loss: 6.7848 - val_accuracy: 0.1337\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 6.4715 - accuracy: 0.1044\n",
            "Epoch 00005: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 6.4715 - accuracy: 0.1044 - val_loss: 3.8880 - val_accuracy: 0.1337\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 6.3046 - accuracy: 0.1082\n",
            "Epoch 00006: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 664ms/step - loss: 6.3046 - accuracy: 0.1082 - val_loss: 3.6737 - val_accuracy: 0.1337\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 5.8862 - accuracy: 0.1072\n",
            "Epoch 00007: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 5.8862 - accuracy: 0.1072 - val_loss: 3.7155 - val_accuracy: 0.1337\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 5.3719 - accuracy: 0.1062\n",
            "Epoch 00008: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 5.3719 - accuracy: 0.1062 - val_loss: 3.6572 - val_accuracy: 0.1337\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 4.7868 - accuracy: 0.1052\n",
            "Epoch 00009: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 4.7868 - accuracy: 0.1052 - val_loss: 3.6713 - val_accuracy: 0.1337\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 4.6259 - accuracy: 0.1064\n",
            "Epoch 00010: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 4.6259 - accuracy: 0.1064 - val_loss: 3.6661 - val_accuracy: 0.1337\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 4.6119 - accuracy: 0.1056\n",
            "Epoch 00011: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 4.6119 - accuracy: 0.1056 - val_loss: 3.6999 - val_accuracy: 0.1337\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 4.4485 - accuracy: 0.1060\n",
            "Epoch 00012: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 4.4485 - accuracy: 0.1060 - val_loss: 3.7025 - val_accuracy: 0.1337\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - ETA: 0s - loss: 4.2651 - accuracy: 0.1060\n",
            "Epoch 00013: val_accuracy did not improve from 0.13371\n",
            "40/40 [==============================] - 27s 665ms/step - loss: 4.2651 - accuracy: 0.1060 - val_loss: 3.6887 - val_accuracy: 0.1337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqxy9KY0IouQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976fbbb8-30bc-4e39-a636-651c42fb2274"
      },
      "source": [
        "test_dir = pathlib.Path(\"/content/drive/MyDrive/Kenyan Sign Language Classification/image_dataset/test\")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=42,\n",
        "  labels=None,\n",
        "  label_mode=None,\n",
        "  image_size=(img_height, img_width)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2679 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJmtQ7CDfWoU"
      },
      "source": [
        "preds = model_1.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO1_Edc4WWZf"
      },
      "source": [
        "submission_file = pd.DataFrame()\n",
        "submission_file[\"ID\"] = test_csv[\"img_IDS\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQe3I1hsYLcQ",
        "outputId": "980c6f6b-42ac-4976-f74d-d606900c9b8e"
      },
      "source": [
        "class_labels = []\n",
        "for name in class_names:\n",
        "  if name == 'Enough Satisfied':\n",
        "    name = 'Enough/Satisfied'\n",
        "  class_labels.append(name)\n",
        "class_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Church',\n",
              " 'Enough/Satisfied',\n",
              " 'Friend',\n",
              " 'Love',\n",
              " 'Me',\n",
              " 'Mosque',\n",
              " 'Seat',\n",
              " 'Temple',\n",
              " 'You']"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "gP-PsLZFQ_Rj",
        "outputId": "83701875-0165-4100-f192-b5c1c1162e7d"
      },
      "source": [
        "for i, c in enumerate(class_labels):\n",
        "  print(c)\n",
        "  submission_file[c] = preds[:,i]\n",
        "submission_file.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Church\n",
            "Enough/Satisfied\n",
            "Friend\n",
            "Love\n",
            "Me\n",
            "Mosque\n",
            "Seat\n",
            "Temple\n",
            "You\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Church</th>\n",
              "      <th>Enough/Satisfied</th>\n",
              "      <th>Friend</th>\n",
              "      <th>Love</th>\n",
              "      <th>Me</th>\n",
              "      <th>Mosque</th>\n",
              "      <th>Seat</th>\n",
              "      <th>Temple</th>\n",
              "      <th>You</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ImageID_USRB8QNG</td>\n",
              "      <td>-0.130174</td>\n",
              "      <td>-0.125592</td>\n",
              "      <td>-0.134458</td>\n",
              "      <td>-0.198543</td>\n",
              "      <td>0.329406</td>\n",
              "      <td>-0.182161</td>\n",
              "      <td>-0.141072</td>\n",
              "      <td>-0.150151</td>\n",
              "      <td>-0.111602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ImageID_SZ8D1ZJI</td>\n",
              "      <td>-0.141298</td>\n",
              "      <td>-0.137476</td>\n",
              "      <td>-0.146483</td>\n",
              "      <td>-0.216054</td>\n",
              "      <td>0.358695</td>\n",
              "      <td>-0.200342</td>\n",
              "      <td>-0.156820</td>\n",
              "      <td>-0.165660</td>\n",
              "      <td>-0.119252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ImageID_4OJO2F8J</td>\n",
              "      <td>-0.198815</td>\n",
              "      <td>-0.185852</td>\n",
              "      <td>-0.200015</td>\n",
              "      <td>-0.290636</td>\n",
              "      <td>0.491497</td>\n",
              "      <td>-0.278846</td>\n",
              "      <td>-0.212158</td>\n",
              "      <td>-0.223665</td>\n",
              "      <td>-0.161406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ImageID_IEE4XV0B</td>\n",
              "      <td>-0.119241</td>\n",
              "      <td>-0.116912</td>\n",
              "      <td>-0.124142</td>\n",
              "      <td>-0.183773</td>\n",
              "      <td>0.304016</td>\n",
              "      <td>-0.169097</td>\n",
              "      <td>-0.132214</td>\n",
              "      <td>-0.139730</td>\n",
              "      <td>-0.101421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ImageID_BP0O0WZ9</td>\n",
              "      <td>-0.137982</td>\n",
              "      <td>-0.135407</td>\n",
              "      <td>-0.144290</td>\n",
              "      <td>-0.210823</td>\n",
              "      <td>0.351782</td>\n",
              "      <td>-0.196935</td>\n",
              "      <td>-0.153554</td>\n",
              "      <td>-0.160082</td>\n",
              "      <td>-0.116322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID    Church  Enough/Satisfied  ...      Seat    Temple       You\n",
              "0  ImageID_USRB8QNG -0.130174         -0.125592  ... -0.141072 -0.150151 -0.111602\n",
              "1  ImageID_SZ8D1ZJI -0.141298         -0.137476  ... -0.156820 -0.165660 -0.119252\n",
              "2  ImageID_4OJO2F8J -0.198815         -0.185852  ... -0.212158 -0.223665 -0.161406\n",
              "3  ImageID_IEE4XV0B -0.119241         -0.116912  ... -0.132214 -0.139730 -0.101421\n",
              "4  ImageID_BP0O0WZ9 -0.137982         -0.135407  ... -0.153554 -0.160082 -0.116322\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y6Km97PLZI6"
      },
      "source": [
        "submission_file.to_csv('/content/drive/MyDrive/Kenyan Sign Language Classification/model_01.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}